# -*- coding: utf-8 -*-
"""Plane2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1InBx8O0CmQn7HpsRIT15N0_iavccMsWx
"""

pip install ultralytics

from google.colab import drive
drive.mount('/content/drive/')

# -*- coding: utf-8 -*-
"""CuoiKy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18A1mzJ7LBGCnko0LnygJlBnbj4X1sreF
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install ultralytics
import ultralytics

"""# ĐẾM ĐỐI TƯỢNG BẰNG YOLOV8
Đếm đối tượng với Ultralytics YOLOv8 liên quan đến việc xác định và đếm chính xác các đối tượng cụ thể trong video và luồng camera. YOLOv8 Vượt trội trong các ứng dụng thời gian thực, cung cấp khả năng đếm đối tượng hiệu quả và chính xác cho các tình huống khác nhau như phân tích và giám sát đám đông, nhờ các thuật toán hiện đại và khả năng học sâu.

Ưu điểm của đếm đối tượng?
- Tối ưu hóa tài nguyên: Đếm đối tượng tạo điều kiện quản lý tài nguyên hiệu quả bằng cách cung cấp số lượng chính xác và tối ưu hóa phân bổ tài nguyên trong các ứng dụng như quản lý hàng tồn kho.
- Tăng cường bảo mật: Đếm đối tượng tăng cường an ninh và giám sát bằng cách theo dõi và đếm chính xác các thực thể, hỗ trợ phát hiện mối đe dọa chủ động.
- Ra quyết định sáng suốt: Đếm đối tượng cung cấp thông tin chi tiết có giá trị cho việc ra quyết định, tối ưu hóa các quy trình trong bán lẻ, quản lý lưu lượng truy cập và nhiều lĩnh vực khác.
"""

import cv2
from ultralytics import YOLO, solutions

# Tải mô hình YOLO phiên bản yolov8n.pt
model = YOLO("yolov8n.pt")

# Mở video từ đường dẫn "/content/Plane.mp4"
cap = cv2.VideoCapture("/content/test3.mp4")

# Kiểm tra xem video có mở thành công không, nếu không thì thông báo lỗi
assert cap.isOpened(), "Error reading video file"

# Lấy thông tin chiều rộng, chiều cao và số khung hình mỗi giây (fps) của video
w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

# Định nghĩa các điểm của vùng quan sát như một đa giác có 4 điểm
region_points = [(600, 720), (650, 720), (650, 0), (600, 0)]

# Khởi tạo video writer để ghi lại video đầu ra với các thông số (định dạng, fps, kích thước)
video_writer = cv2.VideoWriter("object_counting_output.avi", cv2.VideoWriter_fourcc(*"mp4v"), fps, (w, h))

# Khởi tạo bộ đếm đối tượng (ObjectCounter) với các tham số:
# - view_img: hiển thị hình ảnh
# - reg_pts: các điểm của vùng quan sát
# - classes_names: tên các lớp đối tượng của mô hình YOLO
# - line_thickness: độ dày của đường kẻ
counter = solutions.ObjectCounter(
    view_img=True,
    reg_pts=region_points,
    classes_names=model.names,
    # draw_tracks=True, # không sử dụng chức năng này
    line_thickness=2,
)

# Vòng lặp để xử lý từng khung hình của video
while cap.isOpened():
    # Đọc một khung hình từ video
    success, im0 = cap.read()

    # Nếu không đọc được khung hình (video đã hết), thoát vòng lặp
    if not success:
        print("Video frame is empty or video processing has been successfully completed.")
        break

    # Sử dụng mô hình YOLO để theo dõi các đối tượng trong khung hình
    tracks = model.track(im0, persist=True, show=False)

    # Đếm các đối tượng trong khung hình và vẽ các thông tin cần thiết lên khung hình
    im0 = counter.start_counting(im0, tracks)

    # Ghi khung hình đã xử lý vào video đầu ra
    video_writer.write(im0)

# Giải phóng các tài nguyên khi hoàn thành
cap.release()
video_writer.release()
cv2.destroyAllWindows()

import cv2
import os
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

# Đường dẫn tới video
video_path = '/content/test4.mp4'

# Tạo thư mục để lưu các frame ảnh
output_dir = '/content/frames'
os.makedirs(output_dir, exist_ok=True)

# Mở video
cap = cv2.VideoCapture(video_path)

# Kiểm tra xem video có mở được không
if not cap.isOpened():
    print("Không thể mở video.")
    exit()

frame_count = 0

while True:
    # Đọc từng frame từ video
    ret, frame = cap.read()

    # Nếu không đọc được frame, kết thúc vòng lặp
    if not ret:
        break

    # Lưu frame ra file ảnh
    frame_path = os.path.join(output_dir, f'frame_{frame_count:04d}.jpg')
    cv2.imwrite(frame_path, frame)

    # Chuyển đổi màu của ảnh từ BGR sang RGB
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Hiển thị frame vừa đọc được với trục tọa độ
    plt.figure(figsize=(10, 6))
    plt.imshow(frame_rgb)
    plt.axis('on')  # Hiển thị trục tọa độ
    plt.xticks(range(0, frame_rgb.shape[1], 200))  # Tạo các tick trên trục x mỗi 200 đơn vị
    plt.yticks(range(0, frame_rgb.shape[0], 100))  # Tạo các tick trên trục y mỗi 100 đơn vị
    plt.show()

    frame_count += 1

    # Đợi 1 ms hoặc phím 'q' được nhấn để thoát
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Giải phóng video
cap.release()
print(f"Đã trích xuất {frame_count} frames từ video.")

"""# Phân đoạn (Instance Segmentation) và theo dõi (Tracking) phiên bản bằng cách sử dụng Ultralytics YOLOv8 YOLOV8
Ultralytics YOLOv8 Phân đoạn phiên bản liên quan đến việc xác định và phác thảo các đối tượng riêng lẻ trong một hình ảnh, cung cấp sự hiểu biết chi tiết về phân bố không gian. Không giống như phân đoạn ngữ nghĩa, nó dán nhãn duy nhất và phân định chính xác từng đối tượng, rất quan trọng cho các nhiệm vụ như phát hiện đối tượng và hình ảnh y tế.

Có hai loại theo dõi phân đoạn phiên bản có sẵn trong Ultralytics gói:
- Phân đoạn phiên bản với các đối tượng lớp: Mỗi đối tượng lớp được gán một màu duy nhất để phân tách trực quan rõ ràng.
- Phân đoạn phiên bản với Object Tracks: Mỗi bản nhạc được thể hiện bằng một màu sắc riêng biệt, tạo điều kiện dễ dàng xác định và theo dõi.

# Phân đoạn phiên bản với các đối tượng lớp
"""

import cv2
from ultralytics import YOLO
from ultralytics.utils.plotting import Annotator, colors
from google.colab.patches import cv2_imshow

# Định nghĩa tên file video đầu ra
output_video_filename = "segmented_video_with_accuracy.avi"  # Thay thế bằng tên file bạn mong muốn

# Tải mô hình phân đoạn (segmentation model)
model = YOLO("yolov8n-seg.pt")
names = model.model.names  # Lấy tên các lớp đối tượng từ mô hình

# Mở video từ đường dẫn "/content/Plane.mp4"
cap = cv2.VideoCapture("/content/test3.mp4")

# Lấy các thuộc tính của video (chiều rộng, chiều cao, số khung hình mỗi giây)
w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

# Tạo một đối tượng ghi video để lưu lại video đầu ra
out = cv2.VideoWriter(output_video_filename, cv2.VideoWriter_fourcc(*"MJPG"), fps, (w, h))

while True:
    ret, im0 = cap.read()  # Đọc một khung hình từ video

    if not ret:  # Nếu không đọc được khung hình, thoát vòng lặp
        print("Video frame is empty or video processing has been successfully completed.")
        break

    # Thực hiện phát hiện và phân đoạn đối tượng
    results = model.predict(im0,)
    annotator = Annotator(im0, line_width=2)  # Khởi tạo Annotator để vẽ các chú thích lên khung hình

    # Xử lý các đối tượng và mặt nạ (nếu có)
    if results[0].masks is not None:
        clss = results[0].boxes.cls.cpu().tolist()  # Lấy danh sách các lớp đối tượng
        masks = results[0].masks.xy  # Lấy danh sách các mặt nạ
        confidences = results[0].boxes.conf.cpu().tolist()  # Lấy danh sách độ tin cậy

        for mask, cls, conf in zip(masks, clss, confidences):  # Duyệt qua từng mặt nạ, lớp và độ tin cậy
            annotator.seg_bbox(mask=mask, mask_color=colors(int(cls), True), det_label=f"{names[int(cls)]}: {conf:.2f}")
            # Vẽ mặt nạ, nhãn và độ tin cậy lên khung hình

    # Ghi khung hình đã được chú thích vào video đầu ra
    out.write(annotator.im)
    # cv2_imshow(im0)  # Hiển thị khung hình đã được chú thích

    # Thoát khi nhấn phím 'q'
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# Giải phóng các tài nguyên
out.release()
cap.release()
cv2.destroyAllWindows()

# In ra thông báo đã lưu kết quả phân đoạn
print(f"Segmentation results saved to: {output_video_filename}")

"""# Phân đoạn phiên bản với Object Tracks"""

import cv2
from ultralytics import YOLO
from ultralytics.utils.plotting import Annotator, colors

# Define the output video file name with .mp4 extension
output_video_filename = "segmented_video_with_accuracy.mp4"  # Replace with your desired file name

# Load the segmentation model
model = YOLO("yolov8n-seg.pt")
names = model.model.names  # Get the class names from the model

# Open the video file from the specified path
cap = cv2.VideoCapture("/content/test3.mp4")

# Get video properties (width, height, frames per second)
w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

# Create a video writer object to save the output video
out = cv2.VideoWriter(output_video_filename, cv2.VideoWriter_fourcc(*"mp4v"), fps, (w, h))

while True:
    ret, im0 = cap.read()  # Read a frame from the video

    if not ret:  # If no frame is read, exit the loop
        print("Video frame is empty or video processing has been successfully completed.")
        break

    # Perform object detection and segmentation
    results = model.predict(im0)
    annotator = Annotator(im0, line_width=2)  # Initialize the Annotator to draw annotations on the frame

    # Process the objects and masks (if any)
    if results[0].masks is not None:
        clss = results[0].boxes.cls.cpu().tolist()  # Get the list of object classes
        masks = results[0].masks.xy  # Get the list of masks
        confidences = results[0].boxes.conf.cpu().tolist()  # Get the list of confidence scores

        for mask, cls, conf in zip(masks, clss, confidences):  # Iterate through each mask, class, and confidence
            annotator.seg_bbox(mask=mask, mask_color=colors(int(cls), True), det_label=f"{names[int(cls)]}: {conf:.2f}")
            # Draw mask, label, and confidence on the frame

    # Write the annotated frame to the output video
    out.write(annotator.im)

    # Exit on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# Release the resources
out.release()
cap.release()
cv2.destroyAllWindows()

# Print a message indicating that the segmentation results have been saved
print(f"Segmentation results saved to: {output_video_filename}")